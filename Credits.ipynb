{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Способы борьбы с несбалансированными классами\n",
    "Eсть два довольно важных момента, которые нужно\n",
    "повторить, потому что некоторые специалисты (в особенности начинающие), как правило,\n",
    "игнорируют их. Первый момент связан с перекрестной проверки.\n",
    "Перекрестная проверка или использование тестового набора позволяют\n",
    "оценить модель машинного обучения с точки зрения того, как она будет\n",
    "работать в будущем. Однако, если мы с помощью тестового набора или\n",
    "перекрестной проверки осуществляем отбор модели или отбор\n",
    "параметров модели, мы «растрачиваем» тестовые данные, а\n",
    "использование тех же самых данных для оценки работы модели в\n",
    "будущем приведет к чрезмерно оптимистичным прогнозам. Поэтому нам\n",
    "необходимо разбить данные на обучающий набор для построения модели,\n",
    "проверочный набор для отбора модели параметров и тестовый набор для\n",
    "оценки качества моделей. Вместо одного разбиения мы можем\n",
    "использовать разбиения перекрестной проверки. Наиболее часто\n",
    "используемым вариантом (как описывалось ранее) является разбиение\n",
    "обучение/тест для оценки, а также использование перекрестной\n",
    "проверки на обучающем наборе для отбора модели и параметров.\n",
    "Второй момент связан с важностью метрики качества или функции\n",
    "оценки, которые используются для отбора модели и оценки модели.\n",
    "Однако в проектах машинного обучения построение\n",
    "модели с высоким значением правильности редко бывает конечной\n",
    "целью. Надо убедиться в том, что метрика, используемая для оценки и отбора\n",
    "модели, является точным приближением решаемой задачи. В реальности\n",
    "классификационные задачи редко характеризуются\n",
    "сбалансированностью классов и зачастую ложно положительные и ложно\n",
    "отрицательные примеры ведут к совершенно различным последствиям."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Методы борьбы с несбаллансированными классами\n",
    "### 1)AUC-ROC \n",
    "### 2)AUC-PR\n",
    "### 3)Logistic Loss\n",
    "### 4)KNeighborsClassifier\n",
    "\n",
    "Примеры несбланасированных классов:\n",
    "медицинская диагностика, обнаружение мошеннических транзакция, классификация текстов\n",
    "\n",
    "Основная проблема, связанная с несбалансированными выборками, состоит в том, что классификаторы минимизируют число неправильных ответов и никак не учитывают цены ошибок. Может возникнуть ситуация,\n",
    "когда выгоднее отнести все объекты к большему классу, не пытаясь как-то выделить объекты маленького\n",
    "класса. Другими словами, при работе с несбалансированными выборками классификаторы получаются очень\n",
    "плохие с точки зрения точности или полноты."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Метрики качества в задачах регрессии\n",
    "### Среднеквадратичная ошибка\n",
    "### Средняя абсолютная ошибка\n",
    "### Коэффициент детерминации\n",
    "### Несимметричные потери\n",
    "\n",
    "## Метрика качества классификации\n",
    "### Доля правильных ответов\n",
    "### Несбалансированные выборки\n",
    "### Цены ошибок\n",
    "#### Выбор метрик влияет на то, как измеряется и сравнивается производительность алгоритмов машинного обучения. Они влияют на то, как вы оцениваете важность различных характеристик в результатах и   ваш окончательный выбор того, какой алгоритм выбрать."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.isnull().sum().max() # проверка на null"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data['Class'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Судя по данным они очень несбалансированные и выдают большинство операций за не мошеннические"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### В данном случае нужно масштабировать Time и Amount"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "data['scaled_amount'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "amount_val = data['scaled_amount'].values\n",
    "time_val = data['scaled_time'].values\n",
    "\n",
    "sns.distplot(amount_val, ax=ax[0], color='y')\n",
    "ax[0].set_title('scaled_amount', fontsize=14)\n",
    "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "sns.distplot(time_val, ax=ax[1], color='g')\n",
    "ax[1].set_title('scaled_time', fontsize=14)\n",
    "ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Данные я разделю методом cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)\n",
    "\n",
    "fraud_data = data.loc[data['Class'] == 1]\n",
    "non_fraud_data = data.loc[data['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_data = pd.concat([fraud_data, non_fraud_data])\n",
    "new_data = normal_distributed_data.sample(frac=1, random_state=42)\n",
    "\n",
    "new_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = new_data.drop('Class', axis=1)\n",
    "y = new_data['Class']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### В данном случае я буду использовать логическую регрессию и метод К ближайших соседей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(X_train, y_train)\n",
    "cross_val_score(logReg, X_train, y_train, cv=5).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KN = KNeighborsClassifier()\n",
    "KN.fit(X_train, y_train)\n",
    "cross_val_score(KN, X_train, y_train, cv=5).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def logistic_roc_curve(log_fpr, log_tpr):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Logistic Regression ROC', fontsize=16)\n",
    "    plt.plot(log_fpr, log_tpr, 'b-', linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.axis([-0.01,1,0,1])\n",
    "    \n",
    "log_reg_pred = cross_val_predict(logReg, X_train, y_train, cv=5,\n",
    "                             method=\"decision_function\")\n",
    "log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\n",
    "logistic_roc_curve(log_fpr, log_tpr)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### При перекрестной проверке значения оказались высоки и у LogisticRegression и у KNeighborsClassifier и у других классификаторов они должны быть высоки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_log_reg = logReg.predict(X_test)\n",
    "\n",
    "y_pred_knear = KN.predict(X_test)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "print('KNears Neighbors:')\n",
    "print(classification_report(y_test, y_pred_knear))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Перекрестная выборка подошла к решения проблемы с несбланасированными данными\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}